# MLfoyInterface

`MLfoyInterface.py` can be used to read trained DNNs from checkpoint files generated by the `DRACO-MLfoy` framework, such that the DNNs can be evaluated with this `pyroot-plotscripts` framework.

## Usage

This interface can be used for different things:
- generating a configuration of plots for the `pyroot_plotscripts` run
- writing C++ code to read DNN checkpoint files, evaluate the DNNs and fill outputs in histograms

### Generating a config
The interface can be execute with `python MLfoyInterface.py` to generate a configuration of plots.
A path to a set of DNNs needs to be specified with the option `-c /path/to/DNNSet/` where the DNN set in its simplest form requires the following directory structure:
```
NAME_OF_DNN_SET
----/DNNS_OF_FIRST_JT_REGION
--------checkpointfiles
----/DNNS_OF_SECOND_JT_REGION
--------checkpointfiles
...
```
From the information found in the DNN set the script generates a config to define which histograms to create containing
- histograms of all input features for each DNN separately (this can be disabled with the option `--disableplots`)
- histograms fo all DNN output nodes for each DNN separately

Further general options include
- `-n` to set the number of bins for the DNN output plots (default is 15)
- `-v` to activate variable binning, where a list of binedges is saved instead of a binrange
- `-o` to specify an output file (default is `autogenerated_plotconfig.py`)

Some more options for cross evaluation and binning optimization are explained below.

### Adding it to the plottingscripts
To activate the evaluation of the DNN set in your `pyroot-plotscripts` run add the path to the DNN set you want to use to the `dnnInterface` dictionary in your `plottingscript` as `"checkpointFiles"`.

The generation of histograms can be activated by adding the path to a config generated from the specified DNN set to the `plot_cfg` variable in your `plottingscript`.
The path needs to be relative to the `configs` directory.
If you set `plot_cfg = None` a default config is generated from the DNN set.


## Configuration Features

In addition to the default generation of a configuration of histograms some more features are currently implemented in the `MLfoyInterface`. These include the option to cross evaluate DNNs and to optimize the binning of discriminator plots.

### Cross evaluation of DNNs
The datasets on which a DNN is trained and evaluated have to be orthogonal to prevent overfitting.
In the current workflow the MC samples are split in half with the `Evt_Odd` flag, so half of the MC events are used to train the DNNs and the other half for evaluation.
To use all of the available MC statistics, two separate DNNs need to be trained on the `Odd/Even` subsamples and subsequently evaluated on the `Even/Odd` subsamples.
The workflow for this is as follows:

- first train separate DNNs with the `DRACO_MLfoy` Framework on the `Odd/Even` subsamples by appending the options `--even` or `--odd` to the execution of the train script (this of course requires a previous preprocessing of `Odd` and `Even` MC events)
- generate a new set of DNNs with the following directory structure:
```
NAME_OF_DNN_SET
----/DNNS_OF_FIRST_JT_REGION
--------/ODD
------------checkpointfiles
--------/EVEN
------------checkpointfiles
----/DNNS_OF_SECOND_JT_REGION
...
```
- generate a new config with the `MLfoyInterface` and specify the option `-x` to activate the cross evaluation setup.
Activating this option creates configurations for input feature histograms and output discriminators for each jet-tag-region by combining the subfolders (`EVEN/ODD`). If the option is not specified when creating the new config, separate plots are created for the subfolder checkpoint files.
- as usual, add the created config to the `plt_config` variable in your `plottingscript`
- check your `config` file and remove the `(Evt_Odd==0)*2.0` selection if it still exists and replace it by `1.0` to select all events and remove the adjusted weight.
- add the variable `Evt_Odd` to your `variable_cfg` if it does not exist yet.
- add the option `crossEvaluation` to your `analysisOptions` dictionary in the `plottingscript` if it does not exist yet and set it to `True`.
If the option is set to `False` the `c++` code that is written will evaluate all DNNs separately, so you also need a `plt_config` that was not created with the `-x` option.

### binning optimization
As a default the output discriminator histograms are created with a homogeneous bin width. 
If you already produced output discriminator plots with a specific DNN set you can rebin your output discriminators for the next iteration by creating a new config file with the`--optimizeBinning` option.
In the current implementation of the rebinning neighbouring bins are merged if the relative statistical uncertainty exceeds a threshold, so you should start with a finer binning.

The following options can be specified:
- `-f` path to the `output_limitInput.root` file which contains the output histograms of the previous run
- `-p` a comma separated list of processes to consider during the rebinning step. The histograms of the processes are combined and the relative statistical uncertainty is evaluated only on the combined histogram
- `-t` value for the relative statistical error threshold
- `-d` name of the discriminator of the output histograms (c.f. `discr` variable in your `plottingscript`) 


